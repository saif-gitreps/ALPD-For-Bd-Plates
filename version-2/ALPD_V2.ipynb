{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pSRI7tqN5Lyl"
      },
      "outputs": [],
      "source": [
        "# Block 1: Import necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    # Image preprocessing parameters\n",
        "    IMAGE_SIZE = (32, 32)  # As mentioned in paper: 32x32 pixels\n",
        "    FEATURE_SIZE = 1024   # 32*32 = 1024 pixel values as features\n",
        "\n",
        "    # KNN parameters\n",
        "    K_NEIGHBORS = 3  # As specified in the paper\n",
        "\n",
        "    # File paths (adjust these to your data structure)\n",
        "    DATA_PATHS = {\n",
        "        'digits': 'path/to/digit_images/',\n",
        "        'keywords': 'path/to/keyword_images/',\n",
        "        'alphabets': 'path/to/alphabet_images/',\n",
        "    }\n",
        "\n",
        "    # Bangladeshi characters as per BRTA regulations (41 possible alphabets)\n",
        "    BRTA_ALPHABETS = [\n",
        "        'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ', 'ঞ',\n",
        "        'ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ', 'ন',\n",
        "        'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', 'শ', 'ষ',\n",
        "        'স', 'হ', 'ড়', 'ঢ়', 'য়', 'ৎ', 'ং', 'ঃ', 'ঁ', '্', 'া'\n",
        "    ]\n",
        "\n",
        "    # Common keywords in Bangladeshi license plates\n",
        "    KEYWORDS = ['ঢাকা', 'মেট্রো', 'পুর', 'খোলী', 'চট্ট', 'সিলেট', 'রাজ', 'বরি']\n",
        "\n",
        "    # Digits 0-9 in Bengali\n",
        "    BENGALI_DIGITS = ['০', '১', '২', '৩', '৪', '৫', '৬', '৭', '৮', '৯']\n",
        "\n",
        "config = Config()"
      ],
      "metadata": {
        "id": "udpBQ1za5Z2q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    \"\"\"\n",
        "    Preprocess image according to the paper's methodology:\n",
        "    1. Convert to grayscale using Y = 0.21R + 0.72G + 0.07B\n",
        "    2. Resize to 32x32\n",
        "    3. Normalize pixel values\n",
        "    \"\"\"\n",
        "    # Read image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    # Convert to grayscale using the formula from paper\n",
        "    if len(img.shape) == 3:\n",
        "        gray = 0.21 * img[:,:,2] + 0.72 * img[:,:,1] + 0.07 * img[:,:,0]\n",
        "        gray = gray.astype(np.uint8)\n",
        "    else:\n",
        "        gray = img\n",
        "\n",
        "    # Resize to fixed size (32x32 as mentioned in paper)\n",
        "    resized = cv2.resize(gray, config.IMAGE_SIZE)\n",
        "\n",
        "    # Normalize pixel values to 0-1 range\n",
        "    normalized = resized.astype(np.float32) / 255.0\n",
        "\n",
        "    return normalized\n",
        "\n",
        "def extract_features(image):\n",
        "    \"\"\"\n",
        "    Extract features from preprocessed image.\n",
        "    As per paper: pixel intensity values are used as features\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        return None\n",
        "\n",
        "    # Flatten the 32x32 image to 1024 feature vector\n",
        "    features = image.flatten()\n",
        "    return features\n",
        "\n",
        "def apply_morphological_operations(image):\n",
        "    \"\"\"\n",
        "    Apply morphological operations (erosion and dilation) as mentioned in paper\n",
        "    \"\"\"\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "\n",
        "    # Erosion followed by dilation (opening operation)\n",
        "    eroded = cv2.erode(image, kernel, iterations=1)\n",
        "    dilated = cv2.dilate(eroded, kernel, iterations=1)\n",
        "\n",
        "    return dilated\n",
        "\n",
        "print(\"Preprocessing functions defined successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOXzB18b52Lb",
        "outputId": "ca2cdb80-d599-408c-ca50-4dd25c4a3ccb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing functions defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.features = []\n",
        "        self.labels = []\n",
        "        self.label_to_class = {}\n",
        "        self.class_to_label = {}\n",
        "\n",
        "    def load_images_from_directory(self, directory, class_name):\n",
        "        \"\"\"Load images from a directory and assign them a class label\"\"\"\n",
        "        if not os.path.exists(directory):\n",
        "            print(f\"Warning: Directory {directory} not found!\")\n",
        "            return\n",
        "\n",
        "        image_files = [f for f in os.listdir(directory)\n",
        "                      if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
        "\n",
        "        print(f\"Loading {len(image_files)} images from {directory} for class '{class_name}'\")\n",
        "\n",
        "        for img_file in image_files:\n",
        "            img_path = os.path.join(directory, img_file)\n",
        "\n",
        "            # Preprocess image\n",
        "            processed_img = preprocess_image(img_path)\n",
        "            if processed_img is None:\n",
        "                continue\n",
        "\n",
        "            # Extract features\n",
        "            features = extract_features(processed_img)\n",
        "            if features is None:\n",
        "                continue\n",
        "\n",
        "            self.features.append(features)\n",
        "            self.labels.append(class_name)\n",
        "\n",
        "    def prepare_datasets(self):\n",
        "        \"\"\"Prepare the complete dataset\"\"\"\n",
        "        print(\"Starting data preparation...\")\n",
        "\n",
        "        # Load digits (0-9)\n",
        "        for i, digit in enumerate(config.BENGALI_DIGITS):\n",
        "            digit_dir = os.path.join(config.DATA_PATHS['digits'], str(i))\n",
        "            self.load_images_from_directory(digit_dir, f\"digit_{digit}\")\n",
        "\n",
        "        # Load keywords\n",
        "        for keyword in config.KEYWORDS:\n",
        "            keyword_dir = os.path.join(config.DATA_PATHS['keywords'], keyword)\n",
        "            self.load_images_from_directory(keyword_dir, f\"keyword_{keyword}\")\n",
        "\n",
        "        # Load alphabets (41 BRTA alphabets)\n",
        "        for alphabet in config.BRTA_ALPHABETS:\n",
        "            alphabet_dir = os.path.join(config.DATA_PATHS['alphabets'], alphabet)\n",
        "            self.load_images_from_directory(alphabet_dir, f\"alphabet_{alphabet}\")\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        self.features = np.array(self.features)\n",
        "        self.labels = np.array(self.labels)\n",
        "\n",
        "        # Create label mappings\n",
        "        unique_labels = np.unique(self.labels)\n",
        "        self.label_to_class = {label: i for i, label in enumerate(unique_labels)}\n",
        "        self.class_to_label = {i: label for i, label in enumerate(unique_labels)}\n",
        "\n",
        "        # Convert string labels to numeric\n",
        "        numeric_labels = np.array([self.label_to_class[label] for label in self.labels])\n",
        "\n",
        "        print(f\"Dataset prepared successfully!\")\n",
        "        print(f\"Total samples: {len(self.features)}\")\n",
        "        print(f\"Feature dimension: {self.features.shape[1]}\")\n",
        "        print(f\"Number of classes: {len(unique_labels)}\")\n",
        "\n",
        "        return self.features, numeric_labels\n",
        "\n",
        "data_loader = DataLoader(config)\n",
        "print(\"Data loader initialized!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5uFf4fR58MD",
        "outputId": "a53e47cf-b421-460d-f0b1-35190d3befb1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loader initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 5: Model Training (KNN with k=3)\n",
        "class BanglaCharacterRecognizer:\n",
        "    def __init__(self, k_neighbors=3):\n",
        "        self.k_neighbors = k_neighbors\n",
        "        self.model = KNeighborsClassifier(n_neighbors=k_neighbors,\n",
        "                                        metric='euclidean',\n",
        "                                        weights='uniform')\n",
        "        self.is_trained = False\n",
        "        self.label_mappings = {}\n",
        "\n",
        "    def train(self, X_train, y_train, label_mappings):\n",
        "        \"\"\"Train the KNN model\"\"\"\n",
        "        print(f\"Training KNN model with k={self.k_neighbors}...\")\n",
        "\n",
        "        self.model.fit(X_train, y_train)\n",
        "        self.label_mappings = label_mappings\n",
        "        self.is_trained = True\n",
        "\n",
        "        print(\"Model training completed!\")\n",
        "\n",
        "    def predict(self, features):\n",
        "        \"\"\"Predict character class for given features\"\"\"\n",
        "        if not self.is_trained:\n",
        "            raise ValueError(\"Model not trained yet!\")\n",
        "\n",
        "        # Ensure features is 2D\n",
        "        if len(features.shape) == 1:\n",
        "            features = features.reshape(1, -1)\n",
        "\n",
        "        predictions = self.model.predict(features)\n",
        "        probabilities = self.model.predict_proba(features)\n",
        "\n",
        "        return predictions, probabilities\n",
        "\n",
        "    def predict_character(self, image_path):\n",
        "        \"\"\"Predict character from image path\"\"\"\n",
        "        # Preprocess image\n",
        "        processed_img = preprocess_image(image_path)\n",
        "        if processed_img is None:\n",
        "            return None, None\n",
        "\n",
        "        # Extract features\n",
        "        features = extract_features(processed_img)\n",
        "        if features is None:\n",
        "            return None, None\n",
        "\n",
        "        # Predict\n",
        "        prediction, probability = self.predict(features)\n",
        "\n",
        "        # Convert numeric prediction back to character\n",
        "        class_name = self.label_mappings['class_to_label'][prediction[0]]\n",
        "        confidence = np.max(probability[0])\n",
        "\n",
        "        return class_name, confidence\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"Save trained model to disk\"\"\"\n",
        "        model_data = {\n",
        "            'model': self.model,\n",
        "            'k_neighbors': self.k_neighbors,\n",
        "            'label_mappings': self.label_mappings,\n",
        "            'is_trained': self.is_trained\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(model_data, f)\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"Load trained model from disk\"\"\"\n",
        "        with open(filepath, 'rb') as f:\n",
        "            model_data = pickle.load(f)\n",
        "\n",
        "        self.model = model_data['model']\n",
        "        self.k_neighbors = model_data['k_neighbors']\n",
        "        self.label_mappings = model_data['label_mappings']\n",
        "        self.is_trained = model_data['is_trained']\n",
        "\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "\n",
        "# Initialize the recognizer\n",
        "recognizer = BanglaCharacterRecognizer(k_neighbors=config.K_NEIGHBORS)\n",
        "print(\"Character recognizer initialized!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA1jSNgS60L8",
        "outputId": "276d5654-4db7-4a33-f059-d10bfc4c02a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character recognizer initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 6: Training Pipeline\n",
        "def train_model():\n",
        "    \"\"\"Complete training pipeline\"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"STARTING TRAINING PIPELINE\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Prepare dataset\n",
        "    features, labels = data_loader.prepare_datasets()\n",
        "\n",
        "    if len(features) == 0:\n",
        "        print(\"No data found! Please check your data paths.\")\n",
        "        return None\n",
        "\n",
        "    # Prepare label mappings\n",
        "    label_mappings = {\n",
        "        'label_to_class': data_loader.label_to_class,\n",
        "        'class_to_label': data_loader.class_to_label\n",
        "    }\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        features, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "    )\n",
        "\n",
        "    print(f\"Training set size: {len(X_train)}\")\n",
        "    print(f\"Test set size: {len(X_test)}\")\n",
        "\n",
        "    # Train the model\n",
        "    recognizer.train(X_train, y_train, label_mappings)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(\"\\nEvaluating model...\")\n",
        "    train_predictions, _ = recognizer.predict(X_train)\n",
        "    test_predictions, _ = recognizer.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Detailed classification report\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(y_test, test_predictions,\n",
        "                              target_names=[label_mappings['class_to_label'][i]\n",
        "                                          for i in range(len(label_mappings['class_to_label']))]))\n",
        "\n",
        "    return recognizer\n",
        "\n",
        "# Uncomment the next line to run training (when you have data)\n",
        "# trained_model = train_model()"
      ],
      "metadata": {
        "id": "F9oX5yU0viA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 7: Inference and Testing Functions\n",
        "def test_single_image(image_path, model):\n",
        "    \"\"\"Test the model on a single image\"\"\"\n",
        "    if not model.is_trained:\n",
        "        print(\"Model not trained yet!\")\n",
        "        return\n",
        "\n",
        "    print(f\"Testing image: {image_path}\")\n",
        "\n",
        "    # Predict character\n",
        "    predicted_class, confidence = model.predict_character(image_path)\n",
        "\n",
        "    if predicted_class is None:\n",
        "        print(\"Failed to process image!\")\n",
        "        return\n",
        "\n",
        "    print(f\"Predicted: {predicted_class}\")\n",
        "    print(f\"Confidence: {confidence:.4f}\")\n",
        "\n",
        "    # Display the image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is not None:\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"Original Image\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Show preprocessed version\n",
        "        processed = preprocess_image(image_path)\n",
        "        if processed is not None:\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(processed, cmap='gray')\n",
        "            plt.title(f\"Processed (32x32)\\nPredicted: {predicted_class}\\nConf: {confidence:.3f}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def batch_test_images(image_directory, model):\n",
        "    \"\"\"Test the model on a batch of images\"\"\"\n",
        "    if not model.is_trained:\n",
        "        print(\"Model not trained yet!\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(image_directory):\n",
        "        print(f\"Directory {image_directory} not found!\")\n",
        "        return\n",
        "\n",
        "    image_files = [f for f in os.listdir(image_directory)\n",
        "                  if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    print(f\"Testing {len(image_files)} images...\")\n",
        "\n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(image_directory, img_file)\n",
        "        predicted_class, confidence = model.predict_character(img_path)\n",
        "\n",
        "        results.append({\n",
        "            'filename': img_file,\n",
        "            'predicted_class': predicted_class,\n",
        "            'confidence': confidence\n",
        "        })\n",
        "\n",
        "    # Create results DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(\"\\nBatch Testing Results:\")\n",
        "    print(results_df.head(10))\n",
        "\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "fCohVsnyv4cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 8: Utility Functions for License Plate Processing\n",
        "def segment_license_plate_characters(plate_image_path):\n",
        "    \"\"\"\n",
        "    Segment individual characters from a license plate image\n",
        "    This implements the segmentation logic from the paper\n",
        "    \"\"\"\n",
        "    img = cv2.imread(plate_image_path)\n",
        "    if img is None:\n",
        "        return []\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Otsu's thresholding\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Apply morphological operations\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    processed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Filter contours based on area and aspect ratio\n",
        "    character_contours = []\n",
        "\n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 100:  # Minimum area threshold\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            aspect_ratio = w / h\n",
        "\n",
        "            # Filter based on typical character aspect ratios\n",
        "            if 0.2 < aspect_ratio < 2.0:\n",
        "                character_contours.append((x, y, w, h))\n",
        "\n",
        "    # Sort contours from left to right\n",
        "    character_contours.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Extract character images\n",
        "    character_images = []\n",
        "    for x, y, w, h in character_contours:\n",
        "        char_img = gray[y:y+h, x:x+w]\n",
        "\n",
        "        # Resize to standard size\n",
        "        char_img_resized = cv2.resize(char_img, config.IMAGE_SIZE)\n",
        "        character_images.append(char_img_resized)\n",
        "\n",
        "    return character_images\n",
        "\n",
        "def recognize_license_plate(plate_image_path, model):\n",
        "    \"\"\"\n",
        "    Complete license plate recognition pipeline\n",
        "    \"\"\"\n",
        "    if not model.is_trained:\n",
        "        print(\"Model not trained yet!\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Processing license plate: {plate_image_path}\")\n",
        "\n",
        "    # Segment characters\n",
        "    character_images = segment_license_plate_characters(plate_image_path)\n",
        "\n",
        "    if not character_images:\n",
        "        print(\"No characters found in the image!\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Found {len(character_images)} characters\")\n",
        "\n",
        "    # Recognize each character\n",
        "    recognized_text = []\n",
        "    confidences = []\n",
        "\n",
        "    for i, char_img in enumerate(character_images):\n",
        "        # Normalize the character image\n",
        "        char_img_norm = char_img.astype(np.float32) / 255.0\n",
        "        features = char_img_norm.flatten()\n",
        "\n",
        "        # Predict character\n",
        "        prediction, probability = model.predict(features)\n",
        "\n",
        "        # Get character class and confidence\n",
        "        class_name = model.label_mappings['class_to_label'][prediction[0]]\n",
        "        confidence = np.max(probability[0])\n",
        "\n",
        "        recognized_text.append(class_name)\n",
        "        confidences.append(confidence)\n",
        "\n",
        "        print(f\"Character {i+1}: {class_name} (confidence: {confidence:.3f})\")\n",
        "\n",
        "    # Combine results\n",
        "    full_text = ''.join([text.split('_')[1] if '_' in text else text for text in recognized_text])\n",
        "    avg_confidence = np.mean(confidences)\n",
        "\n",
        "    print(f\"Recognized License Plate: {full_text}\")\n",
        "    print(f\"Average Confidence: {avg_confidence:.3f}\")\n",
        "\n",
        "    return {\n",
        "        'text': full_text,\n",
        "        'individual_characters': recognized_text,\n",
        "        'confidences': confidences,\n",
        "        'average_confidence': avg_confidence\n",
        "    }\n",
        "\n",
        "print(\"All functions defined successfully!\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"IMPLEMENTATION COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nTo use this code:\")\n",
        "print(\"1. Update the data paths in Config class\")\n",
        "print(\"2. Organize your data in the specified directory structure\")\n",
        "print(\"3. Run train_model() to train the KNN classifier\")\n",
        "print(\"4. Use test_single_image() or recognize_license_plate() for inference\")\n",
        "print(\"\\nExample usage:\")\n",
        "print(\"# Train model\")\n",
        "print(\"trained_model = train_model()\")\n",
        "print(\"\\n# Test single character\")\n",
        "print(\"test_single_image('path/to/character.jpg', trained_model)\")\n",
        "print(\"\\n# Recognize full license plate\")\n",
        "print(\"result = recognize_license_plate('path/to/license_plate.jpg', trained_model)\")"
      ],
      "metadata": {
        "id": "9agU8Ym6wLFO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}